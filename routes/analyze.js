// routes/analyze.js
const express   = require('express');
const multer    = require('multer');
const fs        = require('fs');
const { OpenAI } = require('openai');

const {
  MODEL_ID,
  SYSTEM_BASE,
  STYLES,
  USER_TEMPLATE
} = require('../config/prompts');

require('dotenv').config();

const router  = express.Router();
const upload  = multer({ dest: 'uploads/' });
const openai  = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

router.post('/', upload.single('handImage'), async (req, res) => {
  try {
    const style   = req.body.style || 'ted';
    const imgPath = req.file?.path;
    if (!imgPath) return res.status(400).json({ error: 'Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½' });

    // Ñ„Ð°Ð¹Ð» â†’ base64
    const img64 = fs.readFileSync(imgPath, 'base64');
    console.log('ðŸ“¸', imgPath, 'base64 length:', img64.length);

    // ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ‹
    const systemPrompt = SYSTEM_BASE + '\n' + (STYLES[style] ?? '');
    const userPrompt   = USER_TEMPLATE;

    // Ð´ÐµÐ»Ð°ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾Ñ
    const chat = await openai.chat.completions.create({
      model: MODEL_ID,
      messages: [
        { role: 'system', content: systemPrompt },
        {
          role   : 'user',
          content: [
            { type: 'text', text: userPrompt },
            {
              type: 'image_url',
              image_url: {
                url   : `data:image/jpeg;base64,${img64}`,
                detail: 'low'
              }
            }
          ]
        }
      ],
      max_tokens: 4096
    });

    const result = chat.choices?.[0]?.message?.content || '';
    console.log('ðŸ“„ length:', result.length,
                'ðŸ’° tokens:', chat.usage?.total_tokens);

    res.json({ result });
  } catch (err) {
    console.error('âŒ', err.message);
    res.status(500).json({ error: 'ÐžÑˆÐ¸Ð±ÐºÐ° Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ' });
  } finally {
    if (req.file?.path) fs.rm(req.file.path, () => {});
  }
});

module.exports = router;
